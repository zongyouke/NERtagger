{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_NER Tagger_Zong-You Ke",
      "provenance": [],
      "collapsed_sections": [
        "uIUnG00_hYl0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkqtpB4hC_A"
      },
      "source": [
        "# M2 project : NER tagging / Zong-You Ke \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tzB0WgQhtH9"
      },
      "source": [
        "This project aims to implement a NER Tagger with Pytorch. We will be using the English CONLL 2003 data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUnG00_hYl0"
      },
      "source": [
        "Data download & description\n",
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCe8as2ej9E0",
        "outputId": "fe8a0f7d-51ef-451f-e75c-80509bac1be2"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.train','eng.train')\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.testa','eng.testa')\n",
        "\n",
        "#Prints the beginning of the training set\n",
        "istream = open('eng.train')\n",
        "for idx, line in enumerate(istream):\n",
        "  print(line.strip())\n",
        "  if idx >=20:\n",
        "  # if idx >=200: # test\n",
        "    break\n",
        "istream.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2f9l5U7mjLz"
      },
      "source": [
        "The CONLL 2003 dataset encodes each token on a single line followed by its annotation. A token line is a quadruple:\n",
        "\n",
        "> (token,tag,chunk,named entity)\n",
        "\n",
        "A named entity tagger aims to predict the named entity annotations given the raw tokens. The NER tags follows the IOB convention. \n",
        "* **I** stands for **Inside** and is used to flag tokens that are part of a named entity.\n",
        "* **B** stands for **Begin** and is used to flag a token starting a new entity when the preceding token is already part of an entity.\n",
        "* **O** stands for **Outside** and is used to flag tokens that are not part of a named entity.\n",
        "\n",
        "The I and B Tag are followed by a specifier. For instance I-PER means that the named entity refers to a person, I-ORG means that the entity is refers to an Organisation.\n",
        "\n",
        "Sentences are separated by a blank line. The train file is `eng.train`, the dev file is `eng.testa`. I will evaluate your work with a test file unknown to you.\n",
        "To do this, I will change the content of the dev file \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mUet-DlpMel"
      },
      "source": [
        "First exercise : data preprocessing (1pts)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAo1csOSpgBh"
      },
      "source": [
        "Using CONLL2003 the train file, you will: \n",
        "\n",
        "* Extract an input vocabulary and create two maps: one mapping tokens to integers and a second mapping integers to tokens (see the pdf notes)\n",
        "* Include elements in the input vocabulary for padding and for unknown words\n",
        "* Extract an output vocabulary (the set of NER tags) and returns two maps \n",
        "mapping tags to integer and vice-versa.\n",
        "\n",
        "These functionalities should be implemented in a function with signature `vocabulary(filename)` that returns the two maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9r8XbqsH8u"
      },
      "source": [
        "# Batch encoding for input symbols\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def vocabulary(filename,input_vocab,padding='<pad>',unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token \n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "        \n",
        "    ###########################\n",
        "    idx2sym = {}\n",
        "    sym2idx = {}\n",
        "    idx = 0\n",
        "    \n",
        "    istream = open(filename)\n",
        "\n",
        "    # parsing entity\n",
        "    for line in istream:\n",
        "      tags = line.strip()\n",
        "      if tags != \"\" and not tags.startswith('-DOCSTART-'):\n",
        "        if input_vocab == 'input': # token\n",
        "          token= tags.split()[0]\n",
        "          if token not in sym2idx.keys(): \n",
        "            sym2idx[token] = idx\n",
        "            idx2sym[idx] = token\n",
        "            idx +=1\n",
        "        elif input_vocab == 'pos': # POS tag\n",
        "          pos = tags.split()[1]\n",
        "          if pos not in sym2idx.keys(): \n",
        "            sym2idx[pos] = idx\n",
        "            idx2sym[idx] = pos\n",
        "            idx +=1\n",
        "\n",
        "        else: # NE tag\n",
        "          ne = tags.split()[-1]\n",
        "          if ne not in sym2idx.keys(): \n",
        "            sym2idx[ne] = idx\n",
        "            idx2sym[idx] = ne\n",
        "            idx +=1\n",
        "            \n",
        "    # padding\n",
        "      sym2idx[padding] = idx\n",
        "      idx2sym[idx] = padding\n",
        "    # unknown\n",
        "      sym2idx[unknown] = idx+1\n",
        "      idx2sym[idx+1] = unknown\n",
        "    \n",
        "\n",
        "    #TODO : return the two vocabulary maps idx2sym and sym2idx\n",
        "    #you have to include two special tokens : padding and unknown symbols\n",
        "\n",
        "    return idx2sym, sym2idx\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba-AGiskRF29"
      },
      "source": [
        "def char_vocabulary(filename,padding='<pad>',unknown='<unk>'):\n",
        "\n",
        "    idx2sym = {}\n",
        "    sym2idx = {}\n",
        "    idx = 0\n",
        "    \n",
        "    with open(filename) as istream:\n",
        "      for line in istream:\n",
        "        tags = line.strip()\n",
        "        if tags != \"\" and not tags.startswith('-DOCSTART-'):\n",
        "          token= tags.split()[0]\n",
        "          for char in token:\n",
        "            if char not in sym2idx.keys():\n",
        "              sym2idx[char] = idx\n",
        "              idx2sym[idx] = char\n",
        "              idx +=1\n",
        "\n",
        "  # padding\n",
        "    sym2idx[padding] = idx\n",
        "    idx2sym[idx] = padding\n",
        "  # unknown\n",
        "    sym2idx[unknown] = idx+1\n",
        "    idx2sym[idx+1] = unknown\n",
        "\n",
        "    return idx2sym, sym2idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M36kJLft0IO"
      },
      "source": [
        "Now we implement three functions: \n",
        "\n",
        "* One that performs padding \n",
        "* The second will encode a sequence of tokens (or a sequence of tags) on integers\n",
        "* The third will decode as sequence of symbols from integers to strings\n",
        "\n",
        "At test time, some tokens might not belong to the vocabulary. Ensure that your encoding function does not crash in this case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV98Rb66uRmz"
      },
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens if needed\n",
        "    ls_pad = [pad_token for i in range(pad_size-len(sequence))]\n",
        "    if len(ls_pad) > 0: sequence.extend(ls_pad)\n",
        "\n",
        "    return sequence\n",
        "\n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    code_seq = []\n",
        "    for elem in sequence:\n",
        "      if elem not in coding_map.keys(): # UNK\n",
        "        code_seq.append(coding_map[unk_token])\n",
        "      else: \n",
        "        code_seq.append(coding_map[elem])\n",
        "\n",
        "    return code_seq\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings \n",
        "    decode_seq = []\n",
        "    for elem in sequence:\n",
        "      decode_seq.append(decoding_map[elem])\n",
        "\n",
        "    return decode_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgFnkj1lOTTS"
      },
      "source": [
        "We then add two more functions for processing characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meIWWhPOME9J"
      },
      "source": [
        "import itertools\n",
        "\n",
        "def pad_char(input, pad_token='<pad>'): \n",
        "    \"\"\"\n",
        "    Separates tokens into characters and make padding \n",
        "    so that of each sequence of characters are of equal length.\n",
        "    \n",
        "    Takes a list of lists of sentences with tokens only, \n",
        "    and returns a list of padded character lists.\n",
        "    \"\"\"\n",
        "    ls_flatten = list(itertools.chain.from_iterable(input))\n",
        "    pad_size_char = len(max(ls_flatten, key=len))\n",
        "\n",
        "    all_tokens = []\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in input:\n",
        "      tokens = []\n",
        "      all_tokens = []\n",
        "      for token in sentence:\n",
        "          if token != pad_token:\n",
        "            ls_pad = [pad_token for i in range(pad_size_char-len(token))]\n",
        "            tokens = [char for char in token]\n",
        "            tokens.extend(ls_pad)\n",
        "          else:\n",
        "            tokens = [pad_token for i in range(pad_size_char)]\n",
        "          all_tokens.append(tokens)\n",
        "      sentences.append(all_tokens)\n",
        "    return sentences\n",
        "\n",
        "def code_char(input,encodingmap):\n",
        "    \"\"\"\n",
        "    Encodes a list of lists of characters and returns a list of lists of characters indices.  \n",
        "    \"\"\"\n",
        "    all_tokens = []\n",
        "    all_sents = []\n",
        "\n",
        "    for sentence in input:\n",
        "      for token in sentence:\n",
        "        tok_codes = [encodingmap[c] for c in token if c in encodingmap]\n",
        "        all_tokens.append(tok_codes)  \n",
        "\n",
        "      all_sents.append(all_tokens)\n",
        "      all_tokens = []\n",
        "\n",
        "    return all_sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj9pkrOv6-xS"
      },
      "source": [
        "Second exercise: data generator (4pts)\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJiBNu737Suv"
      },
      "source": [
        "In this second exercise, we will write a mini-batch generator. \n",
        "This is a class in charge of generating randomized batches of data from the dataset. We start by implementing two functions for reading the textfile\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP3mMhU58Lgu"
      },
      "source": [
        "def read_conll_tokens(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    istream = open(conllfilename)\n",
        "\n",
        "    tokens = []\n",
        "    sentences = []\n",
        "\n",
        "    for line in istream:\n",
        "      tags = line.strip()\n",
        "      if not tags.startswith('-DOCSTART-'):\n",
        "        if tags !=\"\":\n",
        "            tokens.append(tags.split()[0])\n",
        "        else:\n",
        "            if len(tokens) > 0: sentences.append(tokens)\n",
        "            tokens = []\n",
        "        \n",
        "    return sentences\n",
        "\n",
        "\n",
        "def read_conll_tags(conllfilename, tag_type):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (NER-tags)\n",
        "    \"\"\"\n",
        "    istream = open(conllfilename)\n",
        "\n",
        "    all_tags = []\n",
        "    sentences = []\n",
        "\n",
        "    for line in istream:\n",
        "      tags = line.strip()\n",
        "      if not tags.startswith('-DOCSTART-'):\n",
        "        if tags !=\"\":\n",
        "          if tag_type: # BIO tags\n",
        "            all_tags.append(tags.split()[-1])\n",
        "          else:        # POS tags\n",
        "            all_tags.append(tags.split()[1])\n",
        "        else:\n",
        "            if len(all_tags) > 0: sentences.append(all_tags)\n",
        "            all_tags = []\n",
        "\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0QpXfMmQ0xz"
      },
      "source": [
        "\n",
        "\n",
        "Now we implement the class. You will rely on the helper functions designed above in order to fill in the blanks in the constructor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol2Hp2rcGNK9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "        #Reuse all relevant helper functions defined above to solve the problems\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx \n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym \n",
        "\n",
        "                  self.char_sym2idx   = parentgenerator.char_sym2idx\n",
        "                  self.char_idx2sym   = parentgenerator.char_idx2sym\n",
        "\n",
        "                  self.tag_sym2idx  = parentgenerator.tag_sym2idx \n",
        "                  self.tag_sym2idx  = parentgenerator.tag_sym2idx \n",
        "\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx \n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym  \n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "\n",
        "                  #Create encoding maps from datafile \n",
        "                  self.input_idx2sym,self.input_sym2idx     = vocabulary(conllfilename,\"input\",pad_token,unk_token)\n",
        "                  self.char_idx2sym,self.char_sym2idx       = char_vocabulary(conllfilename,pad_token,unk_token)\n",
        "                  self.tag_idx2sym,self.tag_sym2idx         = vocabulary(conllfilename,\"pos\",pad_token,unk_token)\n",
        "                  self.output_idx2sym,self.output_sym2idx   = vocabulary(conllfilename,\"output\",pad_token,unk_token)\n",
        "\n",
        "              #Store the conll dataset with sentence structure (a list of lists of strings) in the following fields \n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename, True)\n",
        "              self.Ttokens = read_conll_tags(conllfilename, False)\n",
        "              #######################\n",
        "\n",
        "        def generate_batches(self,batch_size,conv_mode='False'):\n",
        "\n",
        "              #This is an example generator function yielding one batch after another\n",
        "              #Batches are lists of lists\n",
        "              \n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "              assert(len(self.Ytokens) == len(self.Ttokens))\n",
        "              \n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #Data ordering (try to explain why these 2 lines make sense...)\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend] \n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)              \n",
        "\n",
        "                 seqX = [ self.Xtokens[idx] for idx in batch_idxes]  \n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqT = [ pad_sequence(self.Ttokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 \n",
        "                 # In convolutive mode, we will do character preprocessing\n",
        "                 if conv_mode:\n",
        "                  seqX = code_char(pad_char(seqX), self.char_sym2idx)\n",
        "                 else:\n",
        "                  seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                \n",
        "                 seqY  = [ code_sequence(seq,self.output_sym2idx,self.unk_token) for seq in seqY]\n",
        "                 seqT  = [ code_sequence(seq,self.tag_sym2idx,self.unk_token) for seq in seqT]\n",
        "                 \n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 assert(len(seqY) == len(seqT))\n",
        "                 yield (seqX,seqY,seqT)\n",
        "                 bstart += batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpt98v1US9-t"
      },
      "source": [
        "Third exercise : implement the tagger (5pts)\n",
        "---------------\n",
        "This is the core exercise. There are three main tasks:\n",
        "* Implement parameter allocation. This implies allocating the embedding layer, the LSTM (or bi-LSTM) layer and the Linear Layer.\n",
        "* Implement the forward method. This method expects a tensor encoding the input and outputs a tensor of predictions\n",
        "* Implement the train method \n",
        "\n",
        "The evaluation (`validate`) method is given and cannot be modified. But it can be used as source of inspiration for implementing the train method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhsQ0d1iLd2n"
      },
      "source": [
        "class CharConvolution(nn.Module):\n",
        "      def __init__(self,windowK,chars_vocab_size,input_embedding_size,output_embedding_size,padding_idx = None,device='cpu'):\n",
        "\n",
        "          super(CharConvolution, self).__init__()\n",
        "          self.input_embedding_size = input_embedding_size\n",
        "          self.output_embedding_size = output_embedding_size\n",
        "          self.conv1d = nn.Conv1d(in_channels=self.input_embedding_size, out_channels=self.output_embedding_size, kernel_size=windowK)\n",
        "          self.embeddings = nn.Embedding(chars_vocab_size, input_embedding_size)\n",
        "          self.conv1d     = self.conv1d.to(device)\n",
        "          self.embeddings = self.embeddings.to(device)\n",
        "\n",
        "      def forward(self,Xinput):\n",
        "   \n",
        "          batch_size = Xinput.shape[0]\n",
        "          seq_length = Xinput.shape[1] \n",
        "          word_length = Xinput.shape[2] \n",
        "          emb = self.embeddings(Xinput)\n",
        "\n",
        "          emb_view = emb.view(emb.shape[0],emb.shape[1]*emb.shape[2],emb.shape[3]) \n",
        "          emb= torch.transpose(emb_view, 1, 2)  # batch,char_emb,nb_all_char\n",
        "          \n",
        "          # filtering\n",
        "          conv_emb = self.conv1d(emb) \n",
        "          \n",
        "          # pooling\n",
        "          pool = nn.MaxPool1d(conv_emb.shape[-1]-seq_length+1, stride=1)\n",
        "          emb_of_word = pool(conv_emb) \n",
        "\n",
        "          emb_of_word_transp = torch.transpose(emb_of_word, 1, 2)\n",
        "          emb_of_word_transp_view = emb_of_word_transp.view(batch_size,seq_length,self.output_embedding_size) \n",
        "  \n",
        "          return  emb_of_word_transp_view\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x6y33H2TKiQ"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator,embedding_size,char_embedding_size,tag_embedding_size,hidden_size,bidirectional,window_size=2,dropout=0,num_layers=1,device='cpu'):\n",
        "        super(NERtagger, self).__init__()        \n",
        "        self.embedding_size      = embedding_size\n",
        "        self.char_embedding_size = char_embedding_size\n",
        "        self.tag_embedding_size  = tag_embedding_size\n",
        "        self.hidden_size         = hidden_size\n",
        "        self.window_size         = window_size\n",
        "        self.allocate_params(traingenerator,device,bidirectional,dropout,num_layers) \n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device,bidirectional,dropout,num_layers):\n",
        "        \n",
        "        #create fields for nn Layers\n",
        "        #########################\n",
        "        bi_factor = 1\n",
        "        if bidirectional: bi_factor = 2\n",
        "\n",
        "        invocab_size    = len(datagenerator.input_idx2sym)\n",
        "        outvocab_size   = len(datagenerator.output_idx2sym)\n",
        "        inchar_size     = len(datagenerator.char_sym2idx)\n",
        "        tag_size        = len(datagenerator.tag_idx2sym)\n",
        "\n",
        "        pad_index       = datagenerator.input_sym2idx[datagenerator.pad_token]\n",
        "        pad_tag_index   = datagenerator.tag_sym2idx[datagenerator.pad_token]\n",
        "        self.embeddings = nn.Embedding(invocab_size,self.embedding_size,padding_idx=pad_index)\n",
        "        self.tag_embeddings  = nn.Embedding(tag_size,self.tag_embedding_size,padding_idx=pad_tag_index)   \n",
        "\n",
        "        self.charE      = CharConvolution(self.window_size,inchar_size,self.char_embedding_size,self.embedding_size,device=device)    \n",
        "        self.lstm       = nn.LSTM(self.embedding_size,self.hidden_size,batch_first=True, bidirectional=bidirectional,dropout=dropout,num_layers=num_layers)\n",
        "        self.lstm_tag   = nn.LSTM(self.embedding_size+self.tag_embedding_size,self.hidden_size,batch_first=True, bidirectional=bidirectional,dropout=dropout,num_layers=num_layers)\n",
        "        \n",
        "        self.linear_out      = nn.Linear(self.hidden_size*bi_factor,outvocab_size)\n",
        "        self.embeddings      = self.embeddings.to(device)\n",
        "        self.tag_embeddings  = self.tag_embeddings.to(device)\n",
        "        self.lstm            = self.lstm.to(device)\n",
        "        self.lstm_tag        = self.lstm_tag.to(device)\n",
        "        self.linear_out      = self.linear_out.to(device)\n",
        "        #########################\n",
        "\n",
        "      def forward(self,Xinput,Tinput=None,conv_mode=False,tag_mode=False):\n",
        "        \n",
        "        if tag_mode and Tinput != None:\n",
        "          Xinput = self.embeddings(Xinput) # batch,seqlen,features\n",
        "          Tinput = self.tag_embeddings(Tinput)\n",
        "\n",
        "          # POS tags attached at the end of each token tensor \n",
        "          concat = torch.cat((Xinput, Tinput),0)\n",
        "          output, (h,c) = self.lstm(concat)\n",
        "\n",
        "          # POS tags inserted after all token tensors\n",
        "          #concat = torch.cat((Xinput, Tinput),2)\n",
        "          #output, (h,c) = self.lstm_tag(concat)\n",
        "\n",
        "        elif conv_mode:\n",
        "          Xinput = self.charE(Xinput)\n",
        "          output, (h,c) = self.lstm(Xinput)\n",
        "\n",
        "        else: \n",
        "          Xinput = self.embeddings(Xinput) # batch,seqlen,features\n",
        "          output, (h,c) = self.lstm(Xinput)\n",
        "          \n",
        "        return self.linear_out(output)\n",
        "\n",
        "      def train(self,traingenerator,validgenerator,epochs,batch_sizes,conv_mode=False,tag_mode=False,device='cpu',learning_rate=0.001): \n",
        "\n",
        "        ############################\n",
        "        #once implemented, it is strongly advised to run this method on a GPU\n",
        "        ############################\n",
        "\n",
        "        self.minloss = 10000000 #the min loss found so far on validation data\n",
        "        \n",
        "        device = torch.device(device)\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        batch_accurracies = []\n",
        "        batch_losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "          for (seqX,seqY,seqT) in traingenerator.generate_batches(batch_sizes,conv_mode):  \n",
        "              X = torch.LongTensor(seqX).to(device)\n",
        "              Y = torch.LongTensor(seqY).to(device) \n",
        "              T = torch.LongTensor(seqT).to(device) \n",
        "              \n",
        "              Yhat = self.forward(X,T,conv_mode,tag_mode)\n",
        "\n",
        "              batch_size,seq_len = Y.shape\n",
        "              Yhat = Yhat.view(batch_size*seq_len,-1)  \n",
        "              Y    = Y.view(batch_size*seq_len)\n",
        "\n",
        "              loss = loss_fnc(Yhat, Y)\n",
        "              batch_losses.append(loss.item())\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              mask    = (Y != pad_index)\n",
        "              Yargmax = torch.argmax(Yhat,dim=1)\n",
        "              correct = torch.sum((Yargmax == Y) * mask)\n",
        "              total   = torch.sum(mask)\n",
        "              batch_accurracies.append(float(correct)/float(total))\n",
        "\n",
        "          L = len(batch_losses)\n",
        "          train_loss = sum(batch_losses)/L\n",
        "\n",
        "          print('Epoch %d:'%(epoch))\n",
        "          print('[train] mean loss = %f | mean accuracy = %f'%(train_loss,sum(batch_accurracies)/L))\n",
        "          self.validate(validgenerator, batch_sizes, device=device, save_min_model=True)\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cpu',save_min_model=False):\n",
        "          \n",
        "          batch_accurracies = []\n",
        "          batch_losses      = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY,_) in datagenerator.generate_batches(batch_size,False):\n",
        "                with torch.no_grad():   \n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device)\n",
        "                \n",
        "                  Yhat = self.forward(X)\n",
        "\n",
        "                  #Flattening and loss computation\n",
        "                  batch_size,seq_len = Y.shape\n",
        "                  Yhat = Yhat.view(batch_size*seq_len,-1)\n",
        "                  Y    = Y.view(batch_size*seq_len)\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask    = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  total   = torch.sum(mask)\n",
        "                  batch_accurracies.append(float(correct)/float(total))\n",
        "\n",
        "          L = len(batch_losses)                  \n",
        "          valid_loss = sum(batch_losses)/L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "          \n",
        "          print('[valid] mean loss = %f | mean accurracy = %f'%(valid_loss,sum(batch_accurracies)/L))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO-d3KVc3kTn"
      },
      "source": [
        "The main program is the following. You are expected to add code for searching for hyperparameters that maximise the validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SoEEEf3uM4"
      },
      "source": [
        "trainset = DataGenerator('eng.train')\n",
        "validset = DataGenerator('eng.testa',parentgenerator = trainset)\n",
        "tagger   = NERtagger(trainset,64,16,64,256,bidirectional=True,dropout=0.4,num_layers=1,device='cuda')  \n",
        "                  # tuple of four numbers: word_emb size, char_emb size, tag size, hid size\n",
        "tagger.train(trainset,validset,20,16,conv_mode=False,tag_mode=False,device='cuda',learning_rate=0.0001) \n",
        "                  # tuple of two numbers: epoch, batch size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTLQvRT5t9L"
      },
      "source": [
        "Fourth exercise : improve the tagger (10pts)\n",
        "----------\n",
        "\n",
        "This exercise is relatively free. You may add improvements to the basic tagger.\n",
        "Note that I expect that improving the management of unknown words and of subword units is key on this task. You may wish to:\n",
        "* Find a way to learn a word embedding for unknown words (word dropout)\n",
        "* Use a BiLSTM rather than a simple LSTM\n",
        "* Use part of speech tags embeddings as additional inputs\n",
        "* Integrate your convolutional word embedding module into the tagger\n",
        "* ...\n",
        "\n",
        "Describe your improvements below and point me out the name(s) of the function(s)\n",
        "where they are implemented. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54NY4nCkLjeE"
      },
      "source": [
        "# Results\n",
        "\n",
        "I implemented the following four methods that may help increase accuracy:\n",
        "\n",
        "1. Search for better hyperparameters (including dropout rate)\n",
        "2. Apply bidirectional LSTM\n",
        "3. Use POS tags \n",
        "4. Add convolutional module\n",
        "\n",
        "Below I will describe these methods and results one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctyniPtXLauE"
      },
      "source": [
        "### 1. Hyperparameters\n",
        "\n",
        "All \"sizes\" are tested with numbers in the form of powers of 2.\n",
        "\n",
        "* **optimizer**: fixed at **Adam** since it learns allows the machine to learn much faster than SGD.\n",
        "\n",
        "* **batch size**: fixed at **16** since greater sizes make accuracy drop due to insufficient update.\n",
        "\n",
        "* **word embbeding size**: fixed at **64**. Between 32, 64 and greater sizes, no significant improvement of accuracy could be observed. However, the training time increases with embedding size.\n",
        "\n",
        "* **hidden size**: fixed at **256** as an optimized choice. With one layer of LSTM and emneddings size of 64, greater hidden sizes generally yield an accuracy at over 0.93, but **the maximum it can reach is around 0.94**. However, the greater the hidden size, the longer the training process takes.\n",
        "\n",
        "* **learning rate**: fixed at **0.0001** since it yields the best results. When it is higher (>0.0001) dev accuracy drops. When it is lower, the machine learns too slow.  \n",
        "\n",
        "* **dropout rate**: **0.4** is preferred. I tested with 0.2, 0.3, 0.4 and 0.5 and found no significant differences between the first three. Conversly, 0.5 did not yield an accuracy of over 0.93 easily.\n",
        "\n",
        "* **number of layers**: **1** is preferred since greater numbers not only make training time longer but also bring no significant improvement, if not worse results. \n",
        "\n",
        "* **epochs**: fixed at **20**. with multiple test results, I came to the conclusion that the overall pattern of an accuracy curve can be observed within 20 epochs.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhnHsNr3LkY4"
      },
      "source": [
        "### 2. BiLSTM\n",
        "\n",
        "* I controlled the \"bidirectional switch\" for nn.LSTM function. I found that LSTM runs slightly faster than biLSTM but the accuracy results the former yielded were not as stably high as the latter.\n",
        "* Therefore, **BiLSTM is preferred**, which could yield a dev accuracy as high as 0.94.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-xia5NJLkwU"
      },
      "source": [
        "### 3. POS tags\n",
        "\n",
        "* I extracted the POS tags for each token and sent them out as **Tinput/T** with datagenerator. In forward, I created a special case \"tag mode\" to determine whether POS tags are taken into consideration and whether LSTM should process them. \n",
        "\n",
        "* In the postive case, POS tags are first converted to embeddings through tag_embeddings function, and then  attached to token tensors (Xinput). They may either be attached to respective tokens to which they belong (concat axis = 0), creating longer tensors; or be inserted after all token tensors, making the whole batch bigger (concat axis = 2) and requiring a different lstm function (defined as self.lstm_tag). \n",
        "\n",
        "* **Results**: accuracy results became terrible at below 0.50 and could reach as low as around 0.30. Varying other hyperparameters did not help much. Does the poor results have anything to do with the concatenation methods?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P40_DznsLynC"
      },
      "source": [
        "### 4. Convolutional module\n",
        "\n",
        "* **Usage**: placed before LSTM, this module serves as a fine-tuner for token embeddings. By slicing up tokens into characters, as well as filtering and pooling character embeddings, I wish to find the best embeddings for each token.\n",
        "\n",
        "\n",
        "* **Architecture**: \n",
        "\n",
        " 1. I created a **class CharConvolution** which defines conv1d and maxpool1d the convolutional module. Its forward function receives tensors made of characters and transforms each character into embeddings in order to determine the best embeddings for each token. \n",
        "\n",
        " 2. To generate adequate tensor input, I added three functions, namely **char_vocabulary**, **pad_char** and **code_char**, which help slice up tokens into characters and build a character index lookup table. When conv_mode is True, datagenerator will turn all token seqences into character sequences and perform the same padding and encoding operations as with normal token sequences.\n",
        "\n",
        " 3. An option of conv mode is added within the forward function of class NERtagger. \n",
        " \n",
        "* **Results**: Results are generally much worse (below 0.70) than pure biLSTM with fine-tuned hyperparameters. Varying character embedding size did not help at all. I wonder what could go wrong with my convolutional pipeline....\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9SHrqK1zW9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}